{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22282e5",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Data Wrangling and Visualization\n",
    "@dog_rates is a popular twitter account known for uploaded images of cute dogs and rating them (mostly above 10). In this project, we will be performing analysis on the data pulled from their twitter page. There are three (3) groups of data:\n",
    "<ul>\n",
    "    <li> Archive data (old tweets from 2015, 2016 and 2017 which is provided)</li>\n",
    "<li>Image prediction (a collection of dog breed prediction based of the images pulled from the twitter page)</li>\n",
    "    <li> More detailed tweet (pulled using ids from the archive) </li>\n",
    "</ul>\n",
    "After wrangling, we will be answering some questions and making beautiful visualizations. Lets get started !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages and twitter api key details\n",
    "from keys import consumer_key, consumer_secret, access_token, access_secret\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b78ad5",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f13418",
   "metadata": {},
   "source": [
    "Use the request library to download the image predictions data and save as tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6687f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\")\n",
    "with open(\"image_predictions.tsv\", \"w\") as file:\n",
    "    file.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the saved image predictions data\n",
    "df_image_pred = pd.read_csv(\"image_predictions.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b9282",
   "metadata": {},
   "source": [
    "Setup Tweepy package using imported twitter API details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5273ab",
   "metadata": {},
   "source": [
    "Directly download the WeRateDogs twitter archive data (twitter-archive-enhanced.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbbb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of tweet ids\n",
    "tweet_ids = df_archive.tweet_id.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce48117",
   "metadata": {},
   "source": [
    "Use Tweepy to fetch more details of WeRateDogs twitter archive data and save (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch tweets using tweet ids from archive-enhanced\n",
    "failed_tweet_pull_count = 0\n",
    "for id in tweet_ids:\n",
    "    try:\n",
    "        start = time.time()\n",
    "        tweet = api.get_status(id, tweet_mode='extended')\n",
    "        with open('tweet_json.txt', 'a') as file:\n",
    "            json.dump(tweet._json, file)\n",
    "            file.write(\"\\n\")\n",
    "        end = time.time()\n",
    "        print(end-start, ' seconds')\n",
    "    except:\n",
    "        failed_tweet_pull_count += 1\n",
    "        print('Could not fetch tweet with id:', id)\n",
    "        \n",
    "print('Could not fetch ', failed_tweet_pull_count, ' Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73dd95",
   "metadata": {},
   "source": [
    "Convert tweet_json.txt to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and append json to list\n",
    "tweet_json_list = list()\n",
    "with open(\"tweet_json.txt\") as file_in:\n",
    "    for line in file_in:\n",
    "        tweet_json_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d537c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet = pd.DataFrame(tweet_json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b897982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.to_csv('tweet_json.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3409e1ed",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a6b7b",
   "metadata": {},
   "source": [
    "### Programmatically view the three datasets in order to identify issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicated columns within the three datasets\n",
    "all_columns = pd.Series(list(df_image_pred) + list(df_tweet) + list(df_archive))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411376f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# return random 15 rows of data in archive dataframe\n",
    "df_archive.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01957c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use pandas info method to assess data\n",
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6062d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas describe method\n",
    "df_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for potential outliers with >10 rating denominator\n",
    "df_archive[df_archive.rating_denominator > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates\n",
    "df_archive.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for retweets\n",
    "df_archive[-df_archive.retweeted_status_id.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3daea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check size of archive data (rows and columns)\n",
    "df_archive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051c825",
   "metadata": {},
   "source": [
    "Apply the same pandas methods to tweet dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ff24a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count num of distinct values in coordinates column\n",
    "df_tweet.coordinates.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count num of distinct values in geo column\n",
    "df_tweet.geo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54834045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#count num of distinct values in is_quote_status column\n",
    "df_tweet.is_quote_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all tweets language is english\n",
    "df_tweet[df_tweet_clean.lang != 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecfb7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for tweet dataframe size\n",
    "df_tweet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac4160",
   "metadata": {},
   "source": [
    "Do the same foe image predictions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4365aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf30ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicated rows\n",
    "df_image_pred.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of image predictions data\n",
    "df_image_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fb6af",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "##### `Tweets` table\n",
    "- created_at column is an object not a datetime\n",
    "- entire columns filled with null value\n",
    "- repeated id column (id and id str)\n",
    "- missing records (2327 instead of 2356)\n",
    "- non original tweets (retweets, quotes, reply)\n",
    "- Unwanted columns (only need created_at, id, retweet_count, favorite_count, full_text)\n",
    "\n",
    "##### `Archive tweets` table\n",
    "- non original tweets (retweets, quotes, reply)\n",
    "- Null values in multiple columns\n",
    "- Wrong datatype for timestamp, floofer, pupper and puppo columns\n",
    "- Wrong value in rating columns (9/11 event mistaken as rating)\n",
    "- Non 10 rating denominator value\n",
    "- Incorrect value for dog stages\n",
    "\n",
    "##### `Image Prediction` table\n",
    "- Underscore used instead of space to seperate words (p1, p2 and p3 columns)\n",
    "- No uniform character case in p1, p2 and p3 values\n",
    "- Erroneous datatypes (p1_dog, p2_dog, p3_dog) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6cb638",
   "metadata": {},
   "source": [
    "#### Tidiness\n",
    "- Same column bearing different title in another table (timestamp/created_at, id/tweet_id, text/full_text)\n",
    "- Tweet text duplicated in tweet and archive table\n",
    "- dog stages in four columns instead of one column in archive table\n",
    "- multiple variables in entities and extended entities column of tweet table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8253e0",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954c9ca",
   "metadata": {},
   "source": [
    "Make a copy of the three datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the data\n",
    "df_archive_clean = df_archive.copy()\n",
    "df_tweet_clean = df_tweet.copy()\n",
    "df_image_pred_clean = df_image_pred.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b790bd",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb60547",
   "metadata": {},
   "source": [
    "#### `Tweets table`: Missing records (2327 instead of 2356)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f79b9b",
   "metadata": {},
   "source": [
    "##### Define\n",
    "compare the tweet ids in the archive df to fetched tweets ids, extract missing tweets and manually test some to confirm its non existence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8232a709",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b474d53",
   "metadata": {},
   "source": [
    "Extract tweets ids from archive df, tweet df and comapare to find missing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_tweet_ids = df_tweet_clean.id.tolist()\n",
    "archive_tweet_ids = df_archive_clean.tweet_id.tolist()\n",
    "missing = list(set(archive_tweet_ids).difference(fetched_tweet_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4322e",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e34ae",
   "metadata": {},
   "source": [
    "Attempt the pull the missing tweets again using tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117725c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in missing:\n",
    "    try:\n",
    "        tweet = api.get_status(id=i, tweet_mode='extended')\n",
    "        print('Found')\n",
    "    except:\n",
    "        print('Not Found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee411b",
   "metadata": {},
   "source": [
    "### Tidiness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837a2f2",
   "metadata": {},
   "source": [
    "#### `Archive` Same column bearing different title in another table (timestamp/created_at, id/tweet_id, text/full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53136a9",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Rename the timestamp column to created_at, tweet_id to id and text to full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce47da66",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fcbd46",
   "metadata": {},
   "source": [
    "Use rename() to change the column names of aformentioned columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c1cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.rename(columns = {'timestamp': 'created_at', 'tweet_id': 'id', 'text': 'full_text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred_clean.rename(columns = {'tweet_id': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8466b0c2",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the columns\n",
    "df_archive_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642b3cd",
   "metadata": {},
   "source": [
    "#### `Archive` Tweet text duplicated in tweet and archive table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f5601",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Delete full text column in archive table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0661435a",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904eecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop full_text column\n",
    "df_archive_clean.drop('full_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f69e5",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print column names\n",
    "df_archive_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02bccd1",
   "metadata": {},
   "source": [
    "#### `Archive` dog stages in three columns instead of one column in archive table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d29e62",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Use pandas melt function to merge doggo, floofer, pupper and puppo column into one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5578a607",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68268e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply melt method\n",
    "df_archive_clean = pd.melt(df_archive_clean, id_vars=['id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'created_at',\n",
    "       'source', 'retweeted_status_id', 'retweeted_status_user_id',\n",
    "       'retweeted_status_timestamp', 'expanded_urls', 'rating_numerator',\n",
    "       'rating_denominator', 'name'], var_name='stage', value_name='stage_value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop stage col and duplicate rows based on id\n",
    "df_archive_clean.drop('stage', axis=1, inplace=True)\n",
    "df_archive_clean = df_archive_clean.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e806c37",
   "metadata": {},
   "source": [
    "Rename column `name` to `dog_name` and `stage_value` to `dog_stage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.rename(columns = {'name': 'dog_name', 'stage_value': 'dog_stage'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04514fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check size of data\n",
    "df_archive_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9b93a",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de7f763",
   "metadata": {},
   "source": [
    "#### `Tweet` multiple variables in entities and extended entities column of tweet table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d65753",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Drop `entities` and  `extended_entities` columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29fe1b",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop both columns\n",
    "df_tweet_clean.drop(['entities', 'extended_entities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f48a4",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check remaining columns\n",
    "df_tweet_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa031644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull up random row from tweet df\n",
    "df_tweet_clean.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53d2de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b98cde13",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4af8f6",
   "metadata": {},
   "source": [
    "#### `Tweet` created_at column is an object not a datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab722eb",
   "metadata": {},
   "source": [
    "#### Define\n",
    "convert created_at column to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba13488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean['created_at'] = pd.to_datetime(df_tweet_clean['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291eb47",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091919ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7cf6c2",
   "metadata": {},
   "source": [
    "#### `Tweet` entire columns filled with null value (geo, coordinates, contributors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b7922",
   "metadata": {},
   "source": [
    "#### Define \n",
    "geo is a deprecated feature while coordinates and contributors access might have been turned off by we_rate_dogs. Drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d22cfb3",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 3 columns (geo, coordinates, contributors)\n",
    "df_tweet_clean.drop(['geo', 'coordinates', 'contributors'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052398a",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffb9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bedbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7083c8",
   "metadata": {},
   "source": [
    "#### `Tweet` non original tweets (retweets, quotes, reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e33da3",
   "metadata": {},
   "source": [
    "#### Define \n",
    "drop all tweets that are retweets, quotes and replies by checking rows with non null values in_reply_to_status_id and quoted_status_id columns. Also check for true value in retweeted column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76901694",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6915ed",
   "metadata": {},
   "source": [
    "Drop all rows with tweet ids in `quoted_status_id` and `in_reply_to_status_id` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean.drop(df_tweet_clean.loc[-df_tweet_clean['in_reply_to_status_id'].isnull()].index, inplace=True)\n",
    "df_tweet_clean.drop(df_tweet_clean.loc[-df_tweet_clean['quoted_status_id'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6464cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweet_clean[df_tweet_clean.retweeted == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3d840",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70609cdf",
   "metadata": {},
   "source": [
    "#### `Tweet` Remove Unwanted columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182c4da",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Select created_at, id, retweet_count, favorite_count and full_text columns. Drop the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b458e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns inside the column_names list\n",
    "column_names = ['id_str', 'truncated',\n",
    "       'display_text_range', 'source', 'in_reply_to_status_id',\n",
    "       'in_reply_to_status_id_str', 'in_reply_to_user_id',\n",
    "       'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'place',\n",
    "       'is_quote_status', 'favorited',\n",
    "       'retweeted', 'possibly_sensitive', 'possibly_sensitive_appealable',\n",
    "       'lang', 'retweeted_status', 'quoted_status_id', 'quoted_status_id_str',\n",
    "       'quoted_status_permalink', 'quoted_status']\n",
    "df_tweet_clean.drop(column_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c2986",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1357c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1922a508",
   "metadata": {},
   "source": [
    "#### `Archive` non original tweets (retweets, quotes, replies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc141382",
   "metadata": {},
   "source": [
    "#### Define \n",
    "drop all tweets that are replies and retweets by checking rows with non null values in_reply_to_status_id and retweeted_status_user_id columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bf56c",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b169a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove reply and retweets in archive table\n",
    "df_archive_clean.drop(df_archive_clean.loc[-df_archive_clean['in_reply_to_status_id'].isnull()].index, inplace=True)\n",
    "df_archive_clean.drop(df_archive_clean.loc[-df_archive_clean['retweeted_status_user_id'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6145c3",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62967745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.in_reply_to_status_id.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8255a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.retweeted_status_user_id.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dbe3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66599e64",
   "metadata": {},
   "source": [
    "#### `Archive` null values in multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861fb9c",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Drop all columns with zero non null value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c0467",
   "metadata": {},
   "source": [
    "Remove columns filled with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aaaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.drop(['in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90432a5",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f398e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a7353",
   "metadata": {},
   "source": [
    "#### `Archive` Wrong datatype for timestamp, floofer, pupper and puppo columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca7e41",
   "metadata": {},
   "source": [
    "#### Define \n",
    "convert timestamp(now created_at) to type datetime. floofer, pupper and puppo columns have been merged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba7bb88",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd25b2fa",
   "metadata": {},
   "source": [
    "Change `created_at` column to type datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean['created_at'] = pd.to_datetime(df_archive_clean['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45165bfe",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef935960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c02b53",
   "metadata": {},
   "source": [
    "#### `Archive` Wrong value in rating columns (9/11 event mistaken as rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942eb89",
   "metadata": {},
   "source": [
    "#### Define\n",
    "merge archive and tweet df. replace rows that has rating_numerator and 11 as rating_denominator with the correct rating found in full_text column using regex to extract the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fd47c",
   "metadata": {},
   "source": [
    "#### Code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9cdae",
   "metadata": {},
   "source": [
    "Left join `archive df` to `tweet df` on `id` and `created_at` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge = pd.merge(df_tweet_clean, df_archive_clean, on=['id', 'created_at'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eee04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge[df_archive_tweet_merge.rating_numerator.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e812912",
   "metadata": {},
   "source": [
    "#### Notice\n",
    "Upon examining the data below, I found out that all data with NaN values in rating_numerator, rating_denominator and name at the same time are all retweets. Will be removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155530d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop tweets that are retweets\n",
    "df_archive_tweet_merge.drop(df_archive_tweet_merge.loc[df_archive_tweet_merge['rating_numerator'].isnull()].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d21d80",
   "metadata": {},
   "source": [
    "Use regex to extract rating from full_text and store in `new_rating` column. Seperate the two values using python split function and assign values to `rating_numerator` and `rating_denominator` columns. Drop `new_rating` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge['new_rating'] = df_archive_tweet_merge.full_text.str.extract('([\\d]*/10)', expand=True)\n",
    "df_archive_tweet_merge['rating_numerator'], df_archive_tweet_merge['rating_denominator'] = df_archive_tweet_merge['new_rating'].str.split('/', 1).str\n",
    "df_archive_tweet_merge.drop('new_rating', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f181f",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fbb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d7ea9",
   "metadata": {},
   "source": [
    "#### Non 10 rating denominator value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ed05d",
   "metadata": {},
   "source": [
    "#### Define\n",
    "There are 12 rows with non rating denominators with have been replaced with NaN. I will drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5101561",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4daa8",
   "metadata": {},
   "source": [
    "Drop 12 samples of data with null values in the rating_denominator column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge.drop(df_archive_tweet_merge.loc[df_archive_tweet_merge['rating_denominator'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e154496",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c575bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a8d38",
   "metadata": {},
   "source": [
    "#### Incorrect value for dog stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ae9b9",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Use regex to filter out puppo, pupper, floofer and doggo where mentioned in the full_text column. Replace the NaN values with Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fefa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply regex\n",
    "df_archive_tweet_merge['dog_stage'] = df_archive_tweet_merge.full_text.str.extract(r'(puppo|pupper|floofer|doggo)', flags=re.IGNORECASE, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35201e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all text in `dog_stage` column to lowercase and replace null values with unknown\n",
    "df_archive_tweet_merge['dog_stage'] = df_archive_tweet_merge['dog_stage'].str.lower()\n",
    "df_archive_tweet_merge['dog_stage'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b515d8",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge['dog_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b52a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_tweet_merge.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644eec0",
   "metadata": {},
   "source": [
    "#### `Image Prediction` Underscore used instead of space to seperate words (p1, p2 and p3 columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e911ae",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Use `Series.str.replace` to replace all underscores with space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2607b",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b915c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace underscore (_) with space\n",
    "df_image_pred_clean.p1 = df_image_pred_clean.p1.str.replace('_', ' ')\n",
    "df_image_pred_clean.p2 = df_image_pred_clean.p2.str.replace('_', ' ')\n",
    "df_image_pred_clean.p3 = df_image_pred_clean.p3.str.replace('_', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af6066",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7446d",
   "metadata": {},
   "source": [
    "#### `Image Prediction` No uniform character case in p1, p2 and p3 values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a46ac",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Change p1, p2 and p3 to lower case using `str.lower`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bee43a",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all text in p1, p2 and p3 to lowercase\n",
    "df_image_pred_clean.p1 = df_image_pred_clean.p1.str.lower()\n",
    "df_image_pred_clean.p2 = df_image_pred_clean.p2.str.lower()\n",
    "df_image_pred_clean.p3 = df_image_pred_clean.p3.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f8f8f4",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred_clean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13afd8",
   "metadata": {},
   "source": [
    "#### `Image Prediction` Erroneous datatypes (p1_dog, p2_dog, p3_dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be5857",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Convert aformentioned columns to type category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7972144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert p1_dog, p2_dog and p3_dog columns to type category\n",
    "df_image_pred_clean.p1_dog = df_image_pred_clean.p1_dog.astype('category')\n",
    "df_image_pred_clean.p2_dog = df_image_pred_clean.p2_dog.astype('category')\n",
    "df_image_pred_clean.p3_dog = df_image_pred_clean.p3_dog.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592c801",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3167a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74b1ba53",
   "metadata": {},
   "source": [
    "### Store Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7b730",
   "metadata": {},
   "source": [
    "Merge the three datasets (recall that tweet and archive has been merged) and save as `twitter_archive_master.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge three datasets\n",
    "twitter_archive_master_merge = pd.merge(df_image_pred_clean, df_archive_tweet_merge, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab59ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "twitter_archive_master_merge.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as csv\n",
    "twitter_archive_master_merge.to_csv('twitter_archive_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96916628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned image predictions data as csv\n",
    "df_image_pred_clean.to_csv('image_pred_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save combination of tweet and archive data as csv\n",
    "df_archive_tweet_merge.to_csv('archive_tweet_merge_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96acb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e54eb638",
   "metadata": {},
   "source": [
    "## Visualization and insights\n",
    "> Having cleaned the data, lets now discover some insights by posing couple of questions and answering them both programmatically and graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the master dataset and store it in variable df\n",
    "df = pd.read_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15768080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change created_at column to type datetime\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6fc1c",
   "metadata": {},
   "source": [
    "### Using the dataset above, I intend to answer these questions:\n",
    "- Which dog breed is most loved (based on likes) ?\n",
    "- Least rated dog in year 2016 ?\n",
    "- Most retweeted dog breed ?\n",
    "- Most prominent word used to describe dogs (word cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column titled year and store the individual year each tweet was made\n",
    "df['year'] = df['created_at'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbbe618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view distinct years present \n",
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617fba9d",
   "metadata": {},
   "source": [
    "### Insight 1: Which dog breed is most loved (based on likes) ?\n",
    "> I will find the sum amount of likes for each dog breed using the p1 and p1_dog column and then the max of all the averages. p1_dog column must be True for the breed predicted to be evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00844a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all rows with p1 column == true\n",
    "p1_dog_true = df[df.p1_dog == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eaeae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the first five row\n",
    "p1_dog_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb30870",
   "metadata": {},
   "source": [
    "Use pandas groupby to perform summation of favorite_count for each dog breed in p1 columns. Plot the data using horizonatal bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_like_rating = p1_dog_true.groupby(['p1'])['favorite_count'].sum().sort_values(ascending=False)\n",
    "plt.title('Top 20 Dogs breeds based on likes', size = 15)\n",
    "rating_fig = dog_like_rating[:20].plot(kind=\"barh\",color=\"green\")\n",
    "rating_fig.figure.set_size_inches(12, 9)\n",
    "rating_fig.set_ylabel('Dog breeds', color = 'black', fontsize = '13')\n",
    "rating_fig.set_xlabel('Num of Likes', color = 'black', fontsize = '13')\n",
    "pd.DataFrame(dog_like_rating[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cedd0f",
   "metadata": {},
   "source": [
    "> From the analysis above, Golden retriever is the most loved dog breed on weRateDogs twitter page with 1459893 total amount of likes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448968f",
   "metadata": {},
   "source": [
    "### Insight 2: Least rated dog in year 2016 ?\n",
    "> Check for abnormal ratings and remove them before getting the average rating of all p1 dog breeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f33d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count number of disting values in rating_numerator\n",
    "p1_dog_true.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select tweets made in 2016\n",
    "p1_dog_true_2016 = p1_dog_true[p1_dog_true.year == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9278842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the mean of rating numerators for each breed\n",
    "least_rated_2016 = p1_dog_true_2016.groupby(['p1'])['rating_numerator'].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68995fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#view result\n",
    "least_rated_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b40934",
   "metadata": {},
   "source": [
    "> bloodhound is the least rated dog breed with average rating of 7.5 in the year 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f728d",
   "metadata": {},
   "source": [
    "### Insight 3: Most retweeted dog breed ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5580639",
   "metadata": {},
   "source": [
    "Sum up retweet count for each dog breed. Use pie chart to plot values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retweet value summation\n",
    "dog_retweet_rating = p1_dog_true.groupby(['p1'])['retweet_count'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the data\n",
    "dog_retweet_rating.iloc[:10].plot(kind='pie', radius=3);\n",
    "plt.title('Top 10 Dogs breeds and their amount of twitter retweets', size=15, pad=200)\n",
    "pd.DataFrame(dog_retweet_rating[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8b90c8",
   "metadata": {},
   "source": [
    "> Golden retriever is the most retweeted dog breed on weRateDogs page. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606aca4",
   "metadata": {},
   "source": [
    "### Word Cloud for prominent dog descriptions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331ea87",
   "metadata": {},
   "source": [
    "Use word cloud and matplotlib to view popular words used by WeRateDogs to describe dogs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b093f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,STOPWORDS\n",
    "text=p1_dog_true.full_text.values\n",
    "wordcloud = WordCloud(\n",
    "    width = 3000,\n",
    "    height = 2000,\n",
    "    background_color = 'black',\n",
    "    stopwords = STOPWORDS).generate(str(text))\n",
    "fig = plt.figure(\n",
    "    figsize = (40, 30),\n",
    "    facecolor = 'k',\n",
    "    edgecolor = 'k')\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c296f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0c8ce35",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86310e",
   "metadata": {},
   "source": [
    "The following insights were discovered after visualization\n",
    "- Bloodhound is the least rated dog breed with average rating of 7.5 in the year 2016.\n",
    "- Golden retriever is the most loved and retweeted dog breed on weRateDogs twitter page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
